{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, rdflib\n",
    "from sklearn import metrics\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "from gensim.models import Word2Vec\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import rdflib.plugins.sparql as sparql, matplotlib.pyplot as plt\n",
    "sys.path.append(os.path.abspath(\"./util\"))\n",
    "from misc import *\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.49 s, sys: 450 ms, total: 2.94 s\n",
      "Wall time: 4.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%store -r uri_type\n",
    "if \"uri_type\" not in locals():\n",
    "    dbpedia_type_graph = rdflib.Graph()\n",
    "    dbpedia_type_graph.parse('./dataset/instance_types_en_uris_it.nt', format=\"nt\" )\n",
    "    dbpedia_type_graph.parse('./dataset/instance_types_en.nt', format=\"nt\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9023728"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walks_path = \"./dataset/embedding_5_7_dbpedia_3.9_infobox_properties_no_literal.nt.txt\"\n",
    "\n",
    "vocab_sequences = get_sequences(walks_path)\n",
    "train_sequences = get_sequences(walks_path)\n",
    "\n",
    "model = Word2Vec(min_count=1, window=5, negative=5, size=100)\n",
    "\n",
    "model.build_vocab(vocab_sequences)\n",
    "model.train(train_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r uri_type\n",
    "if \"uri_type\" not in locals():\n",
    "    uri_type = dict()\n",
    "    for uri in model.vocab:\n",
    "        types = {row[0].n3() for row in get_types(uri, dbpedia_type_graph)}\n",
    "        if len(types) > 0:\n",
    "            uri_type[uri] = types\n",
    "    %store uri_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.33 s, sys: 269 ms, total: 2.6 s\n",
      "Wall time: 2.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "embeds = np.asarray([model[uri] for uri in uri_type])\n",
    "uris   = np.asarray([uri for uri in uri_type])\n",
    "labels = get_ground_truth(uris, uri_type) # np.asarray([1 if is_person(mid, mid2types) else 0 for mid in mid2types])\n",
    "###\n",
    "random_idx = np.random.choice(range(len(embeds)), len(embeds), replace=False)\n",
    "split_point = len(embeds) * 70 / 100\n",
    "training_idx, test_idx = random_idx[:split_point], random_idx[split_point:]\n",
    "\n",
    "embeds_train, embeds_test = embeds[training_idx], embeds[test_idx]\n",
    "uris_train,   uris_test   = uris[training_idx],   uris[test_idx]\n",
    "labels_train, labels_test = labels[training_idx], labels[test_idx]\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "# %store -r twodims_dbpedia\n",
    "# if \"twodims_dbpedia\" not in locals():\n",
    "#     twodims_dbpedia = tsne.fit_transform(embeds)\n",
    "#     %store twodims_dbpedia\n",
    "# \n",
    "# ground_truth = get_ground_truth(mids, mid2types)\n",
    "# colors = [get_color(i) for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.rcParams[\"figure.figsize\"] = [14, 10]\n",
    "# x = [point[0] for point in twodims_dbpedia]\n",
    "# y = [point[1] for point in twodims_dbpedia]\n",
    "# plt.scatter(x, y, color=colors)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ovo_rbf    = OneVsOneClassifier(SVC(gamma=2, C=1))\n",
    "# ovo_forest = OneVsOneClassifier(RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1))\n",
    "# ovr_rbf    = OneVsRestClassifier(SVC(gamma=2, C=1))\n",
    "# ovr_forest = OneVsRestClassifier(RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1))\n",
    "\n",
    "ovo_rbf.fit(embeds_train, labels_train)\n",
    "# ovo_forest.fit(embeds_train, labels_train)\n",
    "# ovr_rbf.fit(embeds_train, labels_train)\n",
    "# ovr_forest.fit(embeds_train, labels_train)\n",
    "\n",
    "ovo_rbf_pred    = np.array([ovo_rbf.predict([emb]) for emb in embeds_test])\n",
    "# ovo_forest_pred = np.array([ovo_forest.predict([emb]) for emb in embeds_test])\n",
    "# ovr_rbf_pred    = np.array([ovr_rbf.predict([emb]) for emb in embeds_test])\n",
    "# ovr_forest_pred = np.array([ovr_forest.predict([emb]) for emb in embeds_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [10, 7]\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(labels_test, ovo_rbf_pred)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0, 1, 2, 3, 4, 5], title='Confusion matrix - RF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r twodims_dbpedia_test\n",
    "if \"twodims_dbpedia_test\" not in locals():\n",
    "    twodims_dbpedia_test = tsne.fit_transform(embeds_test)\n",
    "    %store twodims_dbpedia_test\n",
    "\n",
    "colors_true = [get_color(i) for i in labels_test]\n",
    "colors_pred = [get_color(i) for i in ovo_rbf_pred]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [20, 20]\n",
    "fig, ax = plt.subplots(nrows=1,ncols=2)\n",
    "x_test = [point[0] for point in twodims_dbpedia_test]\n",
    "y_test = [point[1] for point in twodims_dbpedia_test]\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.scatter(x_test, y_test, color=colors_true)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(x_test, y_test, color=colors_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_class_df = pd.concat([\n",
    "    multiclass_metrics(labels_test, ovo_rbf_pred, average=\"weighted\", name=\"OnevOne RBF SVM\"),\n",
    "    multiclass_metrics(labels_test, ovo_forest_pred, average=\"weighted\", name=\"OnevOne Forest\"),\n",
    "    multiclass_metrics(labels_test, ovr_rbf_pred, average=\"weighted\", name=\"OnevRest RBF SVM\"),\n",
    "    multiclass_metrics(labels_test, ovr_forest_pred, average=\"weighted\", name=\"OnevRest Forest\")\n",
    "])\n",
    "\n",
    "metrics_class_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
