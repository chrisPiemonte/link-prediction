{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, rdflib\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "from gensim.models import Word2Vec\n",
    "import rdflib.plugins.sparql as sparql\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "sys.path.append(os.path.abspath(\"./util\"))\n",
    "from misc import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import plotly.plotly as py, plotly.graph_objs as go\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "from sklearn import metrics\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.cluster import DBSCAN, KMeans, SpectralClustering, AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.67 s, sys: 588 ms, total: 3.26 s\n",
      "Wall time: 5.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%store -r uri_type\n",
    "if \"uri_type\" not in locals():\n",
    "    dbpedia_type_graph = rdflib.Graph()\n",
    "    dbpedia_type_graph.parse('./dataset/instance_types_en_uris_it.nt', format=\"nt\" )\n",
    "    dbpedia_type_graph.parse('./dataset/instance_types_en.nt', format=\"nt\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # mapping freebase's mids to dbpedia's resources\n",
    "# mid2dbpedia = dict()\n",
    "# file_path = \"./dataset/Release/freebase_code_names.txt\"\n",
    "# with open(file_path, \"r\") as mapping_file:\n",
    "#     for line in mapping_file:\n",
    "#         mid, dbp_resource = line.replace(\"\\n\", \"\").split(\"\\t\")\n",
    "#         val = mid2dbpedia.get(mid, [])\n",
    "#         mid2dbpedia[mid] = val + [dbp_resource]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22615403"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walks_path = \"./dataset/embedding_9_15_dbpedia_3.9_infobox_properties_no_literal.nt.txt\"\n",
    "\n",
    "vocab_sequences = get_sequences(walks_path)\n",
    "train_sequences = get_sequences(walks_path)\n",
    "\n",
    "model = Word2Vec(min_count=1, window=5, negative=5, size=100, sg=1)\n",
    "\n",
    "model.build_vocab(vocab_sequences)\n",
    "model.train(train_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%store -r uri_type\n",
    "if \"uri_type\" not in locals():\n",
    "    uri_type = dict()\n",
    "    for uri in model.vocab:\n",
    "        types = {row[0].n3() for row in get_types(uri, dbpedia_type_graph)}\n",
    "        if len(types) > 0:\n",
    "            uri_type[uri] = types\n",
    "    %store uri_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = np.asarray([model[uri] for uri in uri_type if uri in model])\n",
    "uris   = np.asarray([uri for uri in uri_type])\n",
    "labels = np.asarray([1 if is_person(uri, uri_type) else 0 for uri in uri_type])\n",
    "\n",
    "random_idx  = np.random.choice(range(len(embeds)), len(embeds), replace=False)\n",
    "split_point = len(embeds) * 70 / 100\n",
    "training_idx, test_idx = random_idx[:split_point], random_idx[split_point:]\n",
    "\n",
    "embeds_train, embeds_test = embeds[training_idx], embeds[test_idx]\n",
    "uris_train,   uris_test   = uris[training_idx]  , uris[test_idx]\n",
    "labels_train, labels_test = labels[training_idx], labels[test_idx]\n",
    "\n",
    "ground_truth = get_ground_truth(uris, uri_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "naive_bayes = GaussianNB()\n",
    "rbf_svm     = SVC(gamma=2, C=1)\n",
    "rand_forest = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
    "ada_boost   = AdaBoostClassifier()\n",
    "\n",
    "naive_bayes.fit(embeds_train, labels_train)\n",
    "rbf_svm.fit(embeds_train, labels_train)\n",
    "rand_forest.fit(embeds_train, labels_train)\n",
    "ada_boost.fit(embeds_train, labels_train)\n",
    "\n",
    "naive_bayes_pred = np.array([naive_bayes.predict([emb]) for emb in embeds_test])\n",
    "rbf_svm_pred     = np.array([rbf_svm.predict([emb]) for emb in embeds_test])\n",
    "rand_forest_pred = np.array([rand_forest.predict([emb]) for emb in embeds_test])\n",
    "ada_boost_pred   = np.array([ada_boost.predict([emb]) for emb in embeds_test])\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=15)\n",
    "classifier.fit(embeds_train, labels_train)\n",
    "labels_pred = np.array([classifier.predict([emb]) for emb in embeds_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.concat([\n",
    "    binclass_metrics(labels_test, labels_pred, name=\"Random Forest\"),\n",
    "    binclass_metrics(labels_test, naive_bayes_pred, name=\"Naive Bayes\"),\n",
    "    binclass_metrics(labels_test, rbf_svm_pred, name=\"RBF SVM\"),\n",
    "    binclass_metrics(labels_test, ada_boost_pred, name=\"AdaBoost\")\n",
    "])\n",
    "\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [10, 7]\n",
    "\n",
    "cnf_matrix = metrics.confusion_matrix(labels_test, labels_pred)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0, 1], title='Confusion matrix - RF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "twodims_dbpedia_test = tsne.fit_transform(embeds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors_true = [get_color(i) for i in labels_test]\n",
    "colors_pred = [get_color(i) for i in labels_pred]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [20, 20]\n",
    "fig, ax = plt.subplots(nrows=1,ncols=2)\n",
    "x_test = [point[0] for point in twodims_dbpedia_test]\n",
    "y_test = [point[1] for point in twodims_dbpedia_test]\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.scatter(x_test, y_test, color=colors_true)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.scatter(x_test, y_test, color=colors_pred)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
